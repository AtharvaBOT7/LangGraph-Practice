{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4d8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04beeef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe0b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGSMITH_PROJECT = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = LANGSMITH_PROJECT\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = HUGGINGFACE_API_KEY\n",
    "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab39d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/agent_exec/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceHubEmbeddings\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595846d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a1ceb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model_name = \"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "852d34d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello. How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 36, 'total_tokens': 46, 'completion_time': 0.009940226, 'prompt_time': 0.010520218, 'queue_time': 0.211247268, 'total_time': 0.020460444}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--30ff400a-8900-452a-81e6-e8e5bb860f99-0', usage_metadata={'input_tokens': 36, 'output_tokens': 10, 'total_tokens': 46})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dd0cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c435172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"data\", glob=\"./*.txt\", loader_cls=TextLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd606c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8389f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/info.txt'}, page_content='John Wick is an American media franchise created by Derek Kolstad. It centers on a neo-noir action thriller film series featuring the eponymous character portrayed by Keanu Reeves. Wick is a legendary hitman who is reluctantly drawn back into the criminal underworld after retiring. The franchise began with the release of John Wick (2014), which was followed by three sequels: Chapter 2 (2017), Chapter 3 – Parabellum (2019), and Chapter 4 (2023).[1][2] Various spin-offs expanded the franchise: the prequel comic book series John Wick: The Book of Rules (2017–2019), the prequel television miniseries The Continental (2023), and the spinoff film Ballerina (2025),[3] all incorporating elements of alternate history.\\n\\nThe films have received critical acclaim, and have been considered one of the greatest action film series of all time.[4][5][6][7] Some critics and publications consider the first film,[a] as well as Chapter 4,[25][26][27] as two of the greatest action films ever made. The films have earned a collective gross of more than $1 billion worldwide.[28]\\n\\nChad Stahelski, Basil Iwanyk, and Erica Lee serve in oversight roles for the John Wick franchise. 87Eleven Productions, Thunder Road Films, and Lionsgate produce the franchise.[29]\\n\\nJohn Wick (2014)\\nMain article: John Wick (film)\\nJohn Wick is a retired assassin who returns to his old ways after a group of Russian gangsters steal his car and kill his puppy which was given to him by his late wife Helen.[33]\\n\\nThe film was developed in 2012. Principal photography began September 25, 2013, and wrapped on December 20, 2013.\\n\\nJohn Wick: Chapter 2 (2017)\\nMain article: John Wick: Chapter 2\\nForced to honor a debt from his past life, John Wick is sent to assassinate a target he has no wish to kill, where he faces betrayal at the hands of his sponsor.\\n\\nPrincipal photography began on October 26, 2015. The film was premiered in February 2017.\\n\\nJohn Wick: Chapter 3 – Parabellum (2019)\\nMain article: John Wick: Chapter 3 – Parabellum\\nJohn Wick is declared excommunicado after killing an international crime lord on Continental grounds, where he sets out to save himself from bounty hunters and assassins.\\n\\nThe third film was announced in October 2016, production began in early 2018 and was released in May 2019.\\n\\nJohn Wick: Chapter 4 (2023)\\nMain article: John Wick: Chapter 4\\nJohn Wick takes his fight against the High Table global as he seeks out more powerful players in the underworld from different countries.\\n\\nIn May 2019, prior to the release of John Wick: Chapter 3 – Parabellum, Chad Stahelski confirmed on a Reddit \"Ask Me Anything\" thread that discussion of another film had arisen.[34] Keanu Reeves had also stated that he would continue as long as the films are successful.[35] Lionsgate announced the film during John Wick 3\\'s opening week, with a scheduled release date of May 21, 2021.[36] In April 2020, though, during an interview with Collider, Stahelski revealed that the film would most likely not make its 2021 release date due to his commitment to The Matrix Resurrections.[1] He also revealed, during the same interview, that a 100-page \"scriptment\" (part script/part outline) had been written for the film.[1] The screenplay was written by Shay Hatten and Michael Finch, as the studio decided to move on from series creator Derek Kolstad.[37][38] Production was due to commence in June 2021 in Paris and Berlin, with additional filming in Japan and New York City.[39] Partly due to the COVID-19 pandemic, the film was released on March 24, 2023.[2] In June 2021, Donnie Yen, Rina Sawayama, Shamier Anderson, Bill Skarsgård, and Hiroyuki Sanada joined the cast.[40][41][42][43] Principal photography began on June 28, 2021.[44] In October 2021, principal photography had wrapped.[45]\\n\\nJohn Wick: Chapter 5 (TBA)\\nIn August 2020, Lionsgate CEO Jon Feltheimer confirmed that a fifth film was also being developed. It was intended to be shot back-to-back with the fourth installment in early 2021, but in March 2021, Lionsgate opted to delay production and move forward with Chapter 4 first.[3][39] In May 2022, Stahelski stated that while Chapter 4 has some \"conclusion\" elements to the story, there would be a fifth installment to the franchise.[46] Stahelski stated that though Chapters 4 and 5 were originally intended to be filmed back-to-back, he didn\\'t feel like he could create two meaningfully successful and separate installments, without some time between each project to grow as a filmmaker;[47] stating that once Chapter 4 is released months later in Japan, he and Reeves will discuss and map out the future of the John Wick movies.[48] He also confirmed that he and Reeves will remain involved in the additional projects of the franchise that are currently in development, though the premise for Chapter 5 is not mapped out yet.[49] Later that same month, following the financial and critical success of Chapter 4, producer Erica Lee stated she was hopeful for a fifth film among projects expanding the universe currently in development.[50] By November 2023 following the resolution of the writers and actors strikes, Lionsgate revealed that work on the script for the fifth film had officially resumed.[51]\\n\\nIn October 2024, Stahelski stated that the script has gone through various iterations, but that it would not move forward until he, Reeves, Iwanyk, and Lee were satisfied with the story. The filmmaker revealed that the project would not continue directly from Chapter 4, but will be a separate storyline.[52] By April 2025, the movie was officially announced at CinemaCon. Reeves will reprise the eponymous role, and Stahelski will direct. Basil Iwanyk, Erica Lee, Stahelski, and Reeves will serve as producers.[53][54][55] The following month, Stahelski explained that the plot will not feature the High Table, and will instead see Wick facing new threats, after completing his confrontations with the previous organization.[56] The project will be a joint-venture production between Lionsgate, Thunder Road Films, and 87Eleven Entertainment.[53][54][55]'),\n",
       " Document(metadata={'source': 'data/info2.txt'}, page_content='Llama 4, released in April 2025 by Meta, represents a major leap in large language model design through its mixture-of-experts (MoE) architecture, which balances efficiency, scale, and multimodal capability. The model lineup includes Llama 4 Scout, a lightweight 17B active parameter model with 16 experts and an industry-leading 10M token context window that runs on a single Nvidia H100 GPU; Llama 4 Maverick, a more robust 17B active parameter model with 128 experts and a 1M token context window designed to challenge GPT-4o and Gemini 2.0 Flash; and Llama 4 Behemoth, currently in training, which scales to 288B active parameters and ~2T total parameters with the goal of surpassing GPT-4.5 and Claude Sonnet 3.7 in STEM reasoning benchmarks. Beyond sheer scale, Llama 4 is multimodal—supporting both text and image inputs with text/code outputs—and multilingual, trained on ~200 languages and optimized for 12 major ones, enabling use cases in vision tasks such as captioning, Q&A, and assistant-style interaction. Meta has also improved governance, reducing refusals of political or contentious questions from 7% in Llama 3.3 to under 2%, signaling stronger alignment and balanced responses. Benchmark results show Scout outperforming Gemma 3 and Mistral 3.1 in efficiency, Maverick rivaling premium closed-source models on reasoning and coding, and Behemoth expected to dominate STEM benchmarks upon release. Strategically, Llama 4 is embedded across Meta’s ecosystem—including WhatsApp, Messenger, Instagram Direct, and the web—supported by Superintelligence Labs and billions in AI investment, while being positioned as a cornerstone of open-weight AI leadership. Although some critics noted gaps in reasoning-focused models during the LlamaCon 2025 launch, Llama 4 overall embodies Meta’s ambition to deliver high-context, cost-effective, globally scalable AI systems that blend innovation, accessibility, and responsible deployment.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b50eb4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2693c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_docs = text_splitter.split_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c6ec9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_strings = [doc.page_content for doc in new_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "534bacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(new_docs, embedding=embeddings) \n",
    "retriever = db.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "391dac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'data/info2.txt'}\n",
      "Llama 4, released in April 2025 by Meta, represents a major leap in large language model design\n",
      "page_content='Llama 4, released in April 2025 by Meta, represents a major leap in large language model design' metadata={'source': 'data/info2.txt'}\n",
      "page_content='scale, Llama 4 is multimodal—supporting both text and image inputs with text/code outputs—and' metadata={'source': 'data/info2.txt'}\n",
      "page_content='upon release. Strategically, Llama 4 is embedded across Meta’s ecosystem—including WhatsApp,' metadata={'source': 'data/info2.txt'}\n"
     ]
    }
   ],
   "source": [
    "query = \"what is llama 4?\"\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "print(docs[0].metadata)\n",
    "print(docs[0].page_content)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5775e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(AgentState):\n",
    "    \n",
    "    message=AgentState[\"messages\"]\n",
    "    \n",
    "    question=message[-1]\n",
    "    \n",
    "    complete_prompt=\"Your task is to provide only the brief answer based on the user query. \\\n",
    "        Don't include too much reasoning. Following is the user query: \" + question\n",
    "    \n",
    "    response = llm.invoke(complete_prompt)\n",
    "    \n",
    "    AgentState['messages'].append(response.content)\n",
    "    \n",
    "    return AgentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e762c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(AgentState):\n",
    "    messages = AgentState['messages']\n",
    "    question = messages[0] \n",
    "\n",
    "    template = \"\"\"Answer the question based only on the following context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    retrieval_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "        )\n",
    "    result = retrieval_chain.invoke(question)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a98083d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Langchain graph\n",
    "from langgraph.graph import Graph\n",
    "workflow4 = Graph()\n",
    "workflow4.add_node(\"LLM\", function_1)\n",
    "workflow4.add_node(\"RAGtool\", function_2)\n",
    "workflow4.add_edge('LLM', 'RAGtool')\n",
    "workflow4.set_entry_point(\"LLM\")\n",
    "workflow4.set_finish_point(\"RAGtool\")\n",
    "app4 = workflow4.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef2a47df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n",
      "\n",
      "To resolve this issue:\n",
      "1. Check your internet connection and try again\n",
      "2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n",
      "3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app4.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8dbf644",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"messages\": [\"Tell me about llama 4 model\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa0933ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'LLM':\n",
      "---\n",
      "{'messages': ['Tell me about llama 4 model', 'Llama 4 is an AI model developed by Meta, designed for natural language processing and understanding.']}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'RAGtool':\n",
      "---\n",
      "Llama 4 is a large language model released by Meta in April 2025, representing a significant advancement in large language model design. It is multimodal, supporting both text and image inputs with text/code outputs. The model lineup includes Llama 4 Scout, which is a lightweight 17B active parameter model.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for output in app4.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72be6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769129b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16040e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7596c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0423a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cce26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
