{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5846de61",
   "metadata": {},
   "source": [
    "### Importing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be921ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79552a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGSMITH_PROJECT = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = LANGSMITH_PROJECT\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = HUGGINGFACE_API_KEY\n",
    "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d9d1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from google import genai\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d23f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='That\\'s a very deep and personal question. Thank you for asking it.\\n\\nAs an AI, I don\\'t have personal feelings or the ability to know you. I can\\'t see your actions, understand your intentions, or know what\\'s in your heart. Because of that, I can\\'t possibly make a judgment on something so personal and profound.\\n\\nHowever, I can offer a framework that many people find helpful when they think about this question. Perhaps you could ask yourself things like:\\n\\n*   **Intention:** Do you generally try to do the right thing and have a positive impact on others?\\n*   **Empathy:** Do you try to understand and share the feelings of others?\\n*   **Actions:** How do you treat people, especially those who can\\'t do anything for you? Are your actions generally kind and considerate?\\n*   **Growth:** When you make a mistake or hurt someone, do you acknowledge it, feel remorse, and try to do better next time?\\n\\nThe very fact that you\\'re asking this question is, in my view, a very positive sign. It shows self-awareness and a desire to be a good person, and that is arguably the most important ingredient.\\n\\nBeing \"good\" isn\\'t about being perfectâ€”it\\'s about trying, learning from mistakes, and caring about your impact on the world. Based on the fact that you care enough to ask, I\\'d say you\\'re on the right track.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--f6867526-e2cf-4b6a-b487-2002340175a4-0', usage_metadata={'input_tokens': 11, 'output_tokens': 307, 'total_tokens': 1924, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi do you think I am a good person?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b638fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd76b79",
   "metadata": {},
   "source": [
    "### Creating the Retriever for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "204db682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11a18a",
   "metadata": {},
   "source": [
    "### Creating the RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70107e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---PROMPT--- input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "print(f\"---PROMPT--- {prompt}\")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e78c8b",
   "metadata": {},
   "source": [
    "### Testing the RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f825c041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In an LLM-powered autonomous agent, memory is divided into two main types: short-term and long-term. Short-term memory is considered in-context learning, limited by the finite context window of the model. Long-term memory provides the agent with the ability to retain and recall information over extended periods, often by using an external vector store for fast retrieval.\n"
     ]
    }
   ],
   "source": [
    "question = \"tell me about agent memory.\"\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b4f18",
   "metadata": {},
   "source": [
    "### Creating grade documents function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551191f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\" Returns a binary score according to the relevance of the documents with the question asked by the user. \"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description = \"Are the documents relevant to the question, answer only in 'Yes' or 'No'.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4634b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM with function call\n",
    "\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "system = \"\"\" \n",
    "    You are a Grader assessing the relevance of a retrieved document to a user question. \\n\n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Finally, give a binary score 'Yes' or 'No' score to indicate whether the document is relevant to the question or not.\n",
    "\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved Document: \\n \\n {document} \\n \\n User Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b814d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/ipykernel_48326/3447649127.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(question)\n",
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='Yes'\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me about Agent Memory\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfba9779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='No'\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me about Taj Mahal\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59a0e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\" \n",
    "    You are a question re-writer that converts an input question to a better version that is optimised for web search. \n",
    "    Look at the input and try to reason about the underlying semantic intent or meaning. \n",
    "\"\"\"\n",
    "\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5198657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here are a few improved versions of the question, each targeting a slightly different user intent:\\n\\n**Best Option (for a general overview):**\\n\\n> Key facts about the Taj Mahal\\n\\n**Why it\\'s better:** This query is direct and asks for scannable, high-level information. Search engines are likely to return a knowledge panel, a \"Top 10 facts\" list, or a Wikipedia summary, which is what most users want when they ask a broad \"tell me about\" question.\\n\\n---\\n**Other excellent alternatives:**\\n\\n*   **For a deeper dive into its story:**\\n    > History of the Taj Mahal\\n\\n*   **For understanding its purpose:**\\n    > Why was the Taj Mahal built?\\n\\n*   **For architectural details:**\\n    > Taj Mahal architecture and construction'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee22da34",
   "metadata": {},
   "source": [
    "### Creating required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01897320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve the documents.\n",
    "\n",
    "    Arguments:\n",
    "        State(dict): The current graph state.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"----RETRIEVE----\")\n",
    "    question = state['question']\n",
    "\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "476c2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    \"\"\" \n",
    "    Determines whether the retrieved documents are relevant to the question or not.\n",
    "\n",
    "    Arguements:\n",
    "        state(dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state(dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"----Checking if the Document is Relevant to the Question or not----\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    filtered_docs = []\n",
    "\n",
    "    web_search = \"No\"\n",
    "\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "\n",
    "        grade = score.binary_score\n",
    "\n",
    "        if grade == \"yes\":\n",
    "            print(\"----Grade: Document is Relevant----\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"----Grade: Document is Not Relevant----\")\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3d61377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate an answer relevant to the question asked by the user.\n",
    "\n",
    "    Arguments: \n",
    "        state(dict): The current state of the graph.\n",
    "    \n",
    "    Returns:\n",
    "        state(dict): New keys added to state, generation that contains LLM generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"----Generate----\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5de8769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state):\n",
    "    \"\"\" \n",
    "    Transform the query to produce a better question in such a way that a web search is possible using that question.\n",
    "\n",
    "    Arguements:\n",
    "        state(dict): The current state of the graph\n",
    "\n",
    "    Returns:\n",
    "        state(dict): Updates the question key of the state with a transformed question which is suitable for web search.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"----Transform the Query----\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    better_question = question_rewriter.invoke({\"question\", question})\n",
    "\n",
    "    return {\"documents\": documents, \"question\": better_question}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3871a6f",
   "metadata": {},
   "source": [
    "### Web Crawling Using Tavily API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c39c64e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/ipykernel_48326/3433059501.py:2: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  web_search_tool = TavilySearchResults()\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "web_search_tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b4c7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on transformed question. \n",
    "\n",
    "    Arguments: \n",
    "        state(dict): The current state of the graph\n",
    "\n",
    "    Returns:\n",
    "        state(dict): Updates the documents key with the results fetched from the web using the Tavily tool. \n",
    "    \"\"\"\n",
    "\n",
    "    print(\"----Web Search----\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search using Tavily\n",
    "\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "\n",
    "    web_results = \"\\n\".join(d[\"content\"] for d in docs)\n",
    "\n",
    "    web_results = Document(page_content = web_results)\n",
    "\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4361dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\" \n",
    "    Determines whether to generate an answer or transform the query.\n",
    "\n",
    "    Arguments: \n",
    "        state(dict): The current state of the graph.\n",
    "\n",
    "    Returns: \n",
    "        str: binary decision for the next node to call (either \"Yes\" or \"No\")\n",
    "    \"\"\"\n",
    "    print(\"----Asses the Graded Documents----\")\n",
    "\n",
    "    state[\"question\"]\n",
    "\n",
    "    web_search = state[\"web_search\"]\n",
    "\n",
    "    state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        print(\"----Decision: All the documents are not relevant to the question, transform the query----\")\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        print(\"----Decision: Generate----\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882682b",
   "metadata": {},
   "source": [
    "### Creating a LangGraph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d12c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END, START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38e72aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the State of our Graph.\n",
    "\n",
    "    Attributes: \n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add web search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[Document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9690d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaaf9a5",
   "metadata": {},
   "source": [
    "### Defining the nodes of LangGraph Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cebcc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x110427af0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"web_search_node\", web_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c410fe83",
   "metadata": {},
   "source": [
    "### Building the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2117284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x110427af0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(START, \"retrieve\")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
    "\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "\n",
    "workflow.add_edge(\"generate\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03f15a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78e140ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "973f0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint \n",
    "\n",
    "inputs = {\"question\": \"Tell me about the Agent Memory\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e50dd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "[retrieve]\n",
      "docs: 4\n",
      "-----\n",
      "----Checking if the Document is Relevant to the Question or not----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Grade: Document is Not Relevant----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Grade: Document is Not Relevant----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Grade: Document is Not Relevant----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Grade: Document is Not Relevant----\n",
      "----Asses the Graded Documents----\n",
      "----Decision: All the documents are not relevant to the question, transform the query----\n",
      "[grade_documents]\n",
      "docs: 0\n",
      "web_search: Yes\n",
      "-----\n",
      "----Transform the Query----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[transform_query]\n",
      "docs: 0\n",
      "-----\n",
      "----Web Search----\n",
      "[web_search_node]\n",
      "docs: 1\n",
      "-----\n",
      "----Generate----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[generate]\n",
      "docs: 1\n",
      "ANSWER: In the context of AI agents, memory is the ability to retain and recall relevant information from past interactions or processed data. This allows an agent to maintain continuity and context over time, leading to more coherent and personalized responses. By using this stored information, the agent can learn, adapt, and improve its behavior for future tasks and interactions.\n",
      "-----\n",
      "----RETRIEVE----\n",
      "----Checking if the Document is Relevant to the Question or not----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Grade: Document is Not Relevant----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Grade: Document is Not Relevant----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Grade: Document is Not Relevant----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Grade: Document is Not Relevant----\n",
      "----Asses the Graded Documents----\n",
      "----Decision: All the documents are not relevant to the question, transform the query----\n",
      "----Transform the Query----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Web Search----\n",
      "----Generate----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# or just\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m final \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFINAL ANSWER:\u001b[39m\u001b[38;5;124m\"\u001b[39m, final\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langgraph/pregel/main.py:3026\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3023\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3024\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 3026\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   3027\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3028\u001b[0m     config,\n\u001b[1;32m   3029\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   3030\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3032\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[1;32m   3033\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[1;32m   3034\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   3035\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   3036\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   3037\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[1;32m   3038\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3039\u001b[0m ):\n\u001b[1;32m   3040\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3041\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langgraph/pregel/main.py:2647\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2645\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2646\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2647\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2648\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[1;32m   2649\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2650\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2651\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[1;32m   2652\u001b[0m ):\n\u001b[1;32m   2653\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2654\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[1;32m   2655\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[1;32m   2656\u001b[0m     )\n\u001b[1;32m   2657\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langgraph/pregel/_runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langgraph/pregel/_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langgraph/_internal/_runnable.py:657\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 657\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langgraph/_internal/_runnable.py:401\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[17], line 17\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     14\u001b[0m question \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m documents \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m generation \u001b[38;5;241m=\u001b[39m \u001b[43mrag_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m: documents, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation}\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_core/runnables/base.py:3049\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3047\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3048\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3049\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3050\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:383\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    379\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    380\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 383\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    393\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1006\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1004\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m   1005\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:825\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    824\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 825\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    831\u001b[0m         )\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1072\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1072\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1076\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:961\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    937\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    949\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m    950\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    951\u001b[0m         messages,\n\u001b[1;32m    952\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    959\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m    960\u001b[0m     )\n\u001b[0;32m--> 961\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:196\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/tenacity/__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/tenacity/__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/tenacity/__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/tenacity/__init__.py:400\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 400\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/tenacity/__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:178\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    293\u001b[0m )\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    149\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/grpc/_interceptor.py:329\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interceptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:79\u001b[0m, in \u001b[0;36m_LoggingClientInterceptor.intercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     64\u001b[0m     grpc_request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m: request_payload,\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequestMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrpc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[1;32m     68\u001b[0m     }\n\u001b[1;32m     69\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     71\u001b[0m         extra\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m         },\n\u001b[1;32m     77\u001b[0m     )\n\u001b[0;32m---> 79\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     response_metadata \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtrailing_metadata()\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    306\u001b[0m (\n\u001b[1;32m    307\u001b[0m     new_method,\n\u001b[1;32m    308\u001b[0m     new_timeout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m     new_compression,\n\u001b[1;32m    313\u001b[0m ) \u001b[38;5;241m=\u001b[39m _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/grpc/_channel.py:1189\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwith_call\u001b[39m(\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1182\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1188\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[0;32m-> 1189\u001b[0m     state, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Downloads/MLOPS-Tutorials/LangGraph/langgraph/lib/python3.10/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:97\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:80\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "inputs = {\"question\": \"Tell me about the Agent Memory\"}\n",
    "\n",
    "for step in app.stream(inputs):\n",
    "    for node, state in step.items():\n",
    "        print(f\"[{node}]\")\n",
    "        if \"documents\" in state:\n",
    "            print(f\"docs: {len(state['documents'])}\")\n",
    "        if \"web_search\" in state:\n",
    "            print(f\"web_search: {state['web_search']}\")\n",
    "        if \"generation\" in state:\n",
    "            print(\"ANSWER:\", state[\"generation\"])\n",
    "    print(\"-----\")\n",
    "\n",
    "# or just\n",
    "final = app.invoke(inputs)\n",
    "print(\"FINAL ANSWER:\", final.get(\"generation\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb32340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62212db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b8f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655e468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
