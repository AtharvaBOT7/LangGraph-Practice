{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15eb86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00a3219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f2bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2614b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "\n",
    "LANGCHAIN_TRACING=os.getenv(\"LANGCHAIN_TRACING\")\n",
    "os.environ[\"LANGCHAIN_TRACING\"] = LANGCHAIN_TRACING\n",
    "\n",
    "LANGSMITH_ENDPOINT = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = LANGSMITH_ENDPOINT\n",
    "\n",
    "LANGSMITH_PROJECT = \"langchain_essentials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120e4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3618c840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have feelings or experiences like humans do. However, I'm here and ready to assist you!\\n\\nHow can I help you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 15, 'total_tokens': 54, 'completion_time': 0.070909091, 'prompt_time': 0.00124623, 'queue_time': 0.020609877, 'total_time': 0.072155321}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--be9b70cb-0c75-48d7-825a-b35aad3330b1-0', usage_metadata={'input_tokens': 15, 'output_tokens': 39, 'total_tokens': 54})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "385b1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.memory import ChatMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba95cde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/ipykernel_43654/25687835.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=model,return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryMemory(llm=model,return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9fdd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"Human\": \"John and Jack are working on a new project on ML\"},\n",
    "    {\"AI\": \"Thats interesting! What is their project about?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "499a9ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content=\"Human: John and Jack are working on a new project on ML\\nAI: That's interesting! What is their project about? \\n\\nNew summary: The human mentions that John and Jack are working on a new project related to machine learning. The AI expresses interest and asks for more details about the project. \\n\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ce6e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98ac98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: John and Jack are working on a new project on ML\n",
      "AI: That's interesting! What is their project about? \n",
      "\n",
      "New summary: The human mentions that John and Jack are working on a new project related to machine learning. The AI expresses interest and asks for more details about the project. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary[\"history\"][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a28937",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"Human\": \"The project is about building a healthcare application.\"},\n",
    "    {\"AI\": \"Thats great! Is it for hospitals or patients?\"}\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"Human\": \"It is for the patients.\"},\n",
    "    {\"AI\": \"Cool, wishing Jack and John all the best\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d190e2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human mentions that John and Jack are working on a new project related to machine learning. The AI expresses interest and asks for more details about the project. The human reveals that the project is focused on building a healthcare application for patients. The AI responds positively and wishes John and Jack all the best.  \\n', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3308f758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='John and Jack are working on a new project on ML', additional_kwargs={}, response_metadata={}), AIMessage(content='Thats interesting! What is their project about?', additional_kwargs={}, response_metadata={}), HumanMessage(content='The project is about building a healthcare application.', additional_kwargs={}, response_metadata={}), AIMessage(content='Thats great! Is it for hospitals or patients?', additional_kwargs={}, response_metadata={}), HumanMessage(content='It is for the patients.', additional_kwargs={}, response_metadata={}), AIMessage(content='Cool, wishing Jack and John all the best', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c733f87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='John and Jack are working on a new project on ML', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Thats interesting! What is their project about?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='The project is about building a healthcare application.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Thats great! Is it for hospitals or patients?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='It is for the patients.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Cool, wishing Jack and John all the best', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a62eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5387a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "673b5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "826038bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_ai_message(\"Hi! How can I help you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b019329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_memory = ConversationSummaryMemory.from_messages(\n",
    "    llm=model,\n",
    "    chat_memory=history,\n",
    "    memory_key=\"summary\",\n",
    "    human_prefix=\"User\",\n",
    "    ai_prefix=\"Assistant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "530b691c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current summary: A user greets the assistant. \\n\\nNew lines of conversation:\\nUser: Hello\\nAssistant: Hi! How can I help you? \\n\\nNew summary: A user greets the assistant, and the assistant responds with a greeting and an offer to help. \\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e73fed2",
   "metadata": {},
   "source": [
    "#### Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "551f3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29299b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda6aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81b4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e3189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d258897a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2b504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e265f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
