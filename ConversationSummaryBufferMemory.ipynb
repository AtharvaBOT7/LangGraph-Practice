{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15eb86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00a3219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f2bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2614b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "\n",
    "LANGCHAIN_TRACING=os.getenv(\"LANGCHAIN_TRACING\")\n",
    "os.environ[\"LANGCHAIN_TRACING\"] = LANGCHAIN_TRACING\n",
    "\n",
    "LANGSMITH_ENDPOINT = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = LANGSMITH_ENDPOINT\n",
    "\n",
    "LANGSMITH_PROJECT = \"langchain_essentials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120e4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3618c840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have feelings or experiences like humans do. However, I'm here and ready to assist you!\\n\\nHow can I help you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 15, 'total_tokens': 54, 'completion_time': 0.070909091, 'prompt_time': 0.00124623, 'queue_time': 0.020609877, 'total_time': 0.072155321}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--be9b70cb-0c75-48d7-825a-b35aad3330b1-0', usage_metadata={'input_tokens': 15, 'output_tokens': 39, 'total_tokens': 54})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "385b1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.memory import ChatMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba95cde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/ipykernel_43654/25687835.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=model,return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryMemory(llm=model,return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9fdd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"Human\": \"John and Jack are working on a new project on ML\"},\n",
    "    {\"AI\": \"Thats interesting! What is their project about?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "499a9ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content=\"Human: John and Jack are working on a new project on ML\\nAI: That's interesting! What is their project about? \\n\\nNew summary: The human mentions that John and Jack are working on a new project related to machine learning. The AI expresses interest and asks for more details about the project. \\n\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ce6e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98ac98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: John and Jack are working on a new project on ML\n",
      "AI: That's interesting! What is their project about? \n",
      "\n",
      "New summary: The human mentions that John and Jack are working on a new project related to machine learning. The AI expresses interest and asks for more details about the project. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary[\"history\"][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a28937",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"Human\": \"The project is about building a healthcare application.\"},\n",
    "    {\"AI\": \"Thats great! Is it for hospitals or patients?\"}\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"Human\": \"It is for the patients.\"},\n",
    "    {\"AI\": \"Cool, wishing Jack and John all the best\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d190e2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human mentions that John and Jack are working on a new project related to machine learning. The AI expresses interest and asks for more details about the project. The human reveals that the project is focused on building a healthcare application for patients. The AI responds positively and wishes John and Jack all the best.  \\n', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3308f758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='John and Jack are working on a new project on ML', additional_kwargs={}, response_metadata={}), AIMessage(content='Thats interesting! What is their project about?', additional_kwargs={}, response_metadata={}), HumanMessage(content='The project is about building a healthcare application.', additional_kwargs={}, response_metadata={}), AIMessage(content='Thats great! Is it for hospitals or patients?', additional_kwargs={}, response_metadata={}), HumanMessage(content='It is for the patients.', additional_kwargs={}, response_metadata={}), AIMessage(content='Cool, wishing Jack and John all the best', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c733f87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='John and Jack are working on a new project on ML', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Thats interesting! What is their project about?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='The project is about building a healthcare application.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Thats great! Is it for hospitals or patients?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='It is for the patients.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Cool, wishing Jack and John all the best', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a62eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5387a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "673b5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "826038bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_ai_message(\"Hi! How can I help you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b019329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_memory = ConversationSummaryMemory.from_messages(\n",
    "    llm=model,\n",
    "    chat_memory=history,\n",
    "    memory_key=\"summary\",\n",
    "    human_prefix=\"User\",\n",
    "    ai_prefix=\"Assistant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "530b691c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current summary: A user greets the assistant. \\n\\nNew lines of conversation:\\nUser: Hello\\nAssistant: Hi! How can I help you? \\n\\nNew summary: A user greets the assistant, and the assistant responds with a greeting and an offer to help. \\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e73fed2",
   "metadata": {},
   "source": [
    "#### Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "551f3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d29299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/ipykernel_43654/2088699057.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  convo_with_summary = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "convo_with_summary = ConversationChain(\n",
    "    llm=model,\n",
    "    memory=ConversationSummaryMemory(llm=model),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cda6aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, how are you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have feelings, but I'm ready to chat! How are you doing today?  😊  \\n\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_with_summary.predict(input=\"Hi, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f81b4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "New summary: The human greets the AI and asks how it is doing. The AI, acknowledging it doesn't have feelings, responds that it's ready to chat and asks how the human is doing.  😊  \n",
      "\n",
      "Human: John and Jack are thinking of launching a new product in summer.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's interesting!  Tell me more about this product. What is it? What makes it special?  😊  Are John and Jack planning to sell it online or in physical stores? \\n\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_with_summary.predict(input=\"John and Jack are thinking of launching a new product in summer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "998e3189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "New summary: The human greets the AI and asks how it is doing. The AI, acknowledging it doesn't have feelings, responds that it's ready to chat and asks how the human is doing.  😊  The human tells the AI about John and Jack's plans to launch a new product in the summer. The AI expresses interest and asks for more details about the product, such as what it is, what makes it special, and how they plan to sell it. 😊  \n",
      "\n",
      "Human: the product aims to help the customers to travel from one location to another\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's interesting!  \\n\\nCan you tell me more about how it helps people travel? Is it a physical product like a vehicle or a service like a ride-sharing app?  \\n\\nKnowing that will help me understand what makes it special and how they plan to sell it. 😊  \\n\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_with_summary.predict(input=\"the product aims to help the customers to travel from one location to another\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d258897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "New summary: The human greets the AI and asks how it is doing. The AI, acknowledging it doesn't have feelings, responds that it's ready to chat and asks how the human is doing.  😊  The human tells the AI about John and Jack's plans to launch a new product in the summer. The AI expresses interest and asks for more details about the product, such as what it is, what makes it special, and how they plan to sell it. 😊  The human explains that the product helps people travel from one location to another. The AI, intrigued, asks for more details about how it accomplishes this, clarifying if it's a physical product or a service.  😊  \n",
      "\n",
      "Human: it will use a single person drone to transport one person at a time with no traffic and delays\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's fascinating!  A single-person drone for transportation?  I've read about the potential of drones for delivery services, but this is a whole new level.  \\n\\nTell me more about how this drone would work.  What kind of range does it have?  How will it navigate safely around obstacles and other aircraft?  And what about weather conditions - would it be able to operate in rain or strong winds?  \\n\\nI'm really curious to learn more about the technical aspects of this product. 😊  \\n\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_with_summary.predict(input=\"it will use a single person drone to transport one person at a time with no traffic and delays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65b2b504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human greets the AI and asks how it is doing. The AI, acknowledging it doesn't have feelings, responds that it's ready to chat and asks how the human is doing.  😊  The human tells the AI about John and Jack's plans to launch a new product in the summer. The AI expresses interest and asks for more details about the product, such as what it is, what makes it special, and how they plan to sell it. 😊  The human explains that the product helps people travel from one location to another using a single-person drone to transport one person at a time with no traffic and delays. The AI is intrigued and asks for more details about how the drone would work, including its range, navigation, safety features, and ability to operate in various weather conditions.  😊  \n",
      "\n",
      "Human: can you summarise the startup's idea?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"John and Jack are launching a new product this summer that uses single-person drones to transport people from one location to another.  \\n\\nTheir idea is to offer a travel solution that bypasses traffic and delays, allowing individuals to travel quickly and efficiently.  \\n\\nI'm curious to learn more about the specifics of how the drones will work, like their range, navigation system, safety precautions, and ability to handle different weather conditions. 😊 \\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_with_summary.predict(input=\"can you summarise the startup's idea?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c30ba0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationSummaryMemory(llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x114bbf520>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x114bed750>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********')), chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, how are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As an AI, I don't have feelings, but I'm ready to chat! How are you doing today?  😊  \\n\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='John and Jack are thinking of launching a new product in summer.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's interesting!  Tell me more about this product. What is it? What makes it special?  😊  Are John and Jack planning to sell it online or in physical stores? \\n\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='the product aims to help the customers to travel from one location to another', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's interesting!  \\n\\nCan you tell me more about how it helps people travel? Is it a physical product like a vehicle or a service like a ride-sharing app?  \\n\\nKnowing that will help me understand what makes it special and how they plan to sell it. 😊  \\n\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='it will use a single person drone to transport one person at a time with no traffic and delays', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's fascinating!  A single-person drone for transportation?  I've read about the potential of drones for delivery services, but this is a whole new level.  \\n\\nTell me more about how this drone would work.  What kind of range does it have?  How will it navigate safely around obstacles and other aircraft?  And what about weather conditions - would it be able to operate in rain or strong winds?  \\n\\nI'm really curious to learn more about the technical aspects of this product. 😊  \\n\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"can you summarise the startup's idea?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"John and Jack are launching a new product this summer that uses single-person drones to transport people from one location to another.  \\n\\nTheir idea is to offer a travel solution that bypasses traffic and delays, allowing individuals to travel quickly and efficiently.  \\n\\nI'm curious to learn more about the specifics of how the drones will work, like their range, navigation system, safety precautions, and ability to handle different weather conditions. 😊 \\n\", additional_kwargs={}, response_metadata={})]), buffer=\"The human greets the AI and asks how it is doing. The AI, acknowledging it doesn't have feelings, responds that it's ready to chat and asks how the human is doing.  😊  The human tells the AI about John and Jack's plans to launch a new product in the summer. The AI expresses interest and asks for more details about the product, such as what it is, what makes it special, and how they plan to sell it. 😊  The human explains that the product helps people travel from one location to another using a single-person drone to transport one person at a time with no traffic and delays. The AI is intrigued and asks for more details about how the drone would work, including its range, navigation, safety features, and ability to operate in various weather conditions.  😊  The human then asks the AI to summarize the startup's idea, which the AI does, explaining that John and Jack are launching a product using single-person drones to transport people quickly and efficiently, bypassing traffic and delays.  The AI also expresses curiosity about the specifics of how the drones will function, such as their range, navigation, safety, and weather capabilities. 😊 \\n\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_with_summary.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1485756c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The human greets the AI and asks how it is doing. The AI, acknowledging it doesn't have feelings, responds that it's ready to chat and asks how the human is doing.  😊  The human tells the AI about John and Jack's plans to launch a new product in the summer. The AI expresses interest and asks for more details about the product, such as what it is, what makes it special, and how they plan to sell it. 😊  The human explains that the product helps people travel from one location to another using a single-person drone to transport one person at a time with no traffic and delays. The AI is intrigued and asks for more details about how the drone would work, including its range, navigation, safety features, and ability to operate in various weather conditions.  😊  The human then asks the AI to summarize the startup's idea, which the AI does, explaining that John and Jack are launching a product using single-person drones to transport people quickly and efficiently, bypassing traffic and delays.  The AI also expresses curiosity about the specifics of how the drones will function, such as their range, navigation, safety, and weather capabilities. 😊 \\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_with_summary.memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75162fee",
   "metadata": {},
   "source": [
    "## Conversation Summary Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61e265f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e552e336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/ipykernel_43654/3173139260.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory2 = ConversationSummaryBufferMemory(llm=model, return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "memory2 = ConversationSummaryBufferMemory(llm=model, return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f9a462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory2.save_context(\n",
    "    {\"input\": \"It will be a bit costly when it launches but eventually we will decrease the prices\"},\n",
    "    {\"output\": \"Yes that is great!\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50448dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory2.save_context(\n",
    "    {\"input\": \"At an even later stage we can add more powerful drones which will be able to transport 3-4 people at a time\"},\n",
    "    {\"output\": \"Oh wow this is very interesting!\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10e8b740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='It will be a bit costly when it launches but eventually we will decrease the prices', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes that is great!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='At an even later stage we can add more powerful drones which will be able to transport 3-4 people at a time', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Oh wow this is very interesting!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory2.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5844f2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='It will be a bit costly when it launches but eventually we will decrease the prices', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes that is great!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='At an even later stage we can add more powerful drones which will be able to transport 3-4 people at a time', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Oh wow this is very interesting!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory2.load_memory_variables({})[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6366aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c03a9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = ConversationChain(\n",
    "    llm = model,\n",
    "    verbose = True,\n",
    "    memory = ConversationSummaryBufferMemory(llm=model, max_token_limit=40)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba6f08ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks the AI about the startup idea. The AI is excited to share that it's a platform connecting local artists with people wanting to commission personalized artwork.  It would allow customers to commission pieces like custom portraits, landscapes, or murals from artists in their community.  The platform would feature artist profiles, pricing, and secure payment and messaging tools. \n",
      "\n",
      "Human: hi how are you\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you! I'm buzzing with excitement about this new startup idea I've been working on.  Want to hear about it?  \\n\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.predict(input=\"hi how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c74e2b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks the AI about the startup idea. The AI is excited to share that it's a platform connecting local artists with people wanting to commission personalized artwork.  It would allow customers to commission pieces like custom portraits, landscapes, or murals from artists in their community.  The platform would feature artist profiles, pricing, and secure payment and messaging tools. The human then greets the AI. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AI: I'm doing well, thank you! I'm buzzing with excitement about this new startup idea I've been working on.  Want to hear about it?  \n",
      "\n",
      "\n",
      "Human: I am working on some documentation related to mathematics\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's fascinating!  Mathematics is such a fundamental and beautiful subject. What kind of documentation are you working on?  \\n\\n(The AI is trying to engage with the human's work while still being enthusiastic about its own project.) \\n\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.predict(input=\"I am working on some documentation related to mathematics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8287a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks the AI about the startup idea. The AI is excited to share that it's a platform connecting local artists with people wanting to commission personalized artwork, allowing customers to commission pieces like custom portraits, landscapes, or murals from artists in their community. It would feature artist profiles, pricing, and secure payment and messaging tools. The human then greets the AI. The AI responds enthusiastically, saying it's doing well and eager to share its new startup idea. It then tries to engage with the human's work on mathematics documentation, expressing interest in the subject.  \n",
      "\n",
      "Human: I am working on problems based on integration\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's fascinating! Integration is such a fundamental concept in mathematics.  Is there a particular type of integration you're focusing on?  For example, are you working with definite integrals, indefinite integrals, or maybe something more specialized like Fourier transforms or line integrals?  \\n\\nI'm eager to learn more about what you're exploring! \\n\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.predict(input=\"I am working on problems based on integration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9987725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks the AI about the startup idea. The AI is excited to share that it's a platform connecting local artists with people wanting to commission personalized artwork, allowing customers to commission pieces like custom portraits, landscapes, or murals from artists in their community. It would feature artist profiles, pricing, and secure payment and messaging tools. The human then greets the AI. The AI responds enthusiastically, saying it's doing well and eager to share its new startup idea. It then tries to engage with the human's work on mathematics documentation, expressing interest in the subject. The AI is particularly interested in the human's focus on integration, asking about the specific type of integration they are working on.  \n",
      "\n",
      "Human: the concept i am working on includes 4th degree of integration\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's fascinating!  Fourth-degree integration is quite advanced.  Could you tell me more about what you're working on specifically?  \\n\\nI'm not familiar with the specific applications of fourth-degree integration, so I'm eager to learn. Are you dealing with any particular mathematical functions or problems that require this level of integration? \\n\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.predict(input=\"the concept i am working on includes 4th degree of integration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d3e647f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks the AI about the startup idea. The AI is excited to share that it's a platform connecting local artists with people wanting to commission personalized artwork, allowing customers to commission pieces like custom portraits, landscapes, or murals from artists in their community. It would feature artist profiles, pricing, and secure payment and messaging tools. The human then greets the AI. The AI responds enthusiastically, saying it's doing well and eager to share its new startup idea. It then tries to engage with the human's work on mathematics documentation, expressing interest in the subject. The AI is particularly interested in the human's focus on integration, asking about the specific type of integration they are working on.  The human reveals they are working with 4th degree integration, which fascinates the AI. The AI then asks for more details about the human's work, expressing its unfamiliarity with the applications of 4th degree integration and its eagerness to learn about the specific functions or problems the human is addressing.  \n",
      "\n",
      "Human: Whats the subject I am workig on?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You mentioned you're working on mathematics documentation, specifically focusing on 4th degree integration.  \\n\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.predict(input=\"Whats the subject I am workig on?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6814a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
