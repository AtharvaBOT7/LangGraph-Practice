{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4afe8de",
   "metadata": {},
   "source": [
    "## Simple Level-1 Workflow with normal functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be40cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func3(input3):\n",
    "    return input3 + \": This is the input from function 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(input1):\n",
    "    return input1 + \": This is the input from function 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf10800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(input2):\n",
    "    output = func3(\"This is function 2 in between\")\n",
    "    return input2 + \" \" + output + \": This is the input from function 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a19e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1 = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1.add_node(\"function1\", func1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ee842",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1.add_node(\"function2\", func2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c41ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1.add_edge(\"function1\",\"function2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a0db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1.set_entry_point(\"function1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d52f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow1.set_finish_point(\"function2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "app1 = workflow1.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7da0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app1.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7825a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app1.invoke(\"Hello I am Atharva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1155fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Hello I am Atharva\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73842ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in app1.stream(input):\n",
    "    for key,value in output.items():\n",
    "        print(f\"here is output from {key}\")\n",
    "        print(\"_______\")\n",
    "        print(value)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d3d9b8",
   "metadata": {},
   "source": [
    "## Let's create a new workflow with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99a2e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f41e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6acd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGSMITH_PROJECT = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = LANGSMITH_PROJECT\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = HUGGINGFACE_API_KEY\n",
    "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec72950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "open_llm = ChatGroq(model_name = \"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f41cbbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello. How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 36, 'total_tokens': 46, 'completion_time': 0.01730791, 'prompt_time': 0.010591019, 'queue_time': 0.212295878, 'total_time': 0.027898929}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_6507bcfb6f', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--fa319834-6cea-48b2-ba0d-92e1baaecc58-0', usage_metadata={'input_tokens': 36, 'output_tokens': 10, 'total_tokens': 46})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d6d0848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/LangGraph/agent_exec/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-gecko-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e054ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(input):\n",
    "    open_llm = ChatGroq(model_name = \"llama-3.3-70b-versatile\")\n",
    "    response = open_llm.invoke(input).content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4945eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2(input):\n",
    "    upper_case = input.upper()\n",
    "    return upper_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fcd4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb35a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow2 = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "124752f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x120a7ea70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow2.add_node(\"llm\", function1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6faf682c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x120a7ea70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow2.add_node(\"convert_upper\", function2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8512d156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x120a7ea70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow2.add_edge(\"llm\",\"convert_upper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66184d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x120a7ea70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow2.set_entry_point(\"llm\")\n",
    "workflow2.set_finish_point(\"convert_upper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "698d0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "app2 = workflow2.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfb4192a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE CURRENT PRIME MINISTER OF INDIA IS NARENDRA MODI. HE HAS BEEN IN OFFICE SINCE MAY 26, 2014, AND IS SERVING HIS SECOND TERM AS PRIME MINISTER.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app2.invoke(\"Who is current Prime Minister of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbdace60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**YES, LEARNING MACHINE LEARNING IS IMPORTANT**. MACHINE LEARNING (ML) HAS BECOME A CRUCIAL ASPECT OF VARIOUS INDUSTRIES, INCLUDING TECHNOLOGY, HEALTHCARE, FINANCE, AND MORE. HERE ARE SOME REASONS WHY LEARNING ML IS ESSENTIAL:\n",
      "\n",
      "1. **INCREASING DEMAND**: THE DEMAND FOR ML EXPERTS IS RISING RAPIDLY, AND HAVING ML SKILLS CAN OPEN UP NEW CAREER OPPORTUNITIES.\n",
      "2. **IMPROVED DECISION-MAKING**: ML HELPS ORGANIZATIONS MAKE INFORMED DECISIONS BY ANALYZING LARGE DATASETS AND PROVIDING INSIGHTS THAT MIGHT BE DIFFICULT TO OBTAIN THROUGH TRADITIONAL METHODS.\n",
      "3. **AUTOMATION AND EFFICIENCY**: ML CAN AUTOMATE REPETITIVE TASKS, FREEING UP RESOURCES FOR MORE STRATEGIC AND CREATIVE WORK.\n",
      "4. **COMPETITIVE ADVANTAGE**: COMPANIES THAT ADOPT ML CAN GAIN A COMPETITIVE EDGE OVER THOSE THAT DON'T, AS ML CAN HELP THEM INNOVATE AND IMPROVE THEIR PRODUCTS AND SERVICES.\n",
      "5. **PROBLEM-SOLVING**: ML CAN BE USED TO SOLVE COMPLEX PROBLEMS, SUCH AS IMAGE AND SPEECH RECOGNITION, NATURAL LANGUAGE PROCESSING, AND PREDICTIVE MODELING.\n",
      "6. **INTERDISCIPLINARY APPLICATIONS**: ML HAS APPLICATIONS IN VARIOUS FIELDS, INCLUDING COMPUTER VISION, ROBOTICS, HEALTHCARE, AND SOCIAL SCIENCES.\n",
      "7. **FUTURE-PROOFING**: AS TECHNOLOGY CONTINUES TO EVOLVE, ML IS LIKELY TO PLAY AN INCREASINGLY IMPORTANT ROLE IN SHAPING THE FUTURE OF INDUSTRIES AND SOCIETIES.\n",
      "\n",
      "**WHO CAN BENEFIT FROM LEARNING MACHINE LEARNING?**\n",
      "\n",
      "1. **DATA SCIENTISTS AND ANALYSTS**: ML IS A KEY SKILL FOR DATA PROFESSIONALS, AS IT ENABLES THEM TO EXTRACT INSIGHTS FROM DATA AND BUILD PREDICTIVE MODELS.\n",
      "2. **SOFTWARE DEVELOPERS**: ML CAN BE USED TO BUILD INTELLIGENT SYSTEMS AND APPLICATIONS, MAKING IT AN ESSENTIAL SKILL FOR DEVELOPERS.\n",
      "3. **BUSINESS PROFESSIONALS**: UNDERSTANDING ML CAN HELP BUSINESS LEADERS MAKE INFORMED DECISIONS AND DRIVE INNOVATION IN THEIR ORGANIZATIONS.\n",
      "4. **RESEARCHERS**: ML CAN BE USED TO ANALYZE AND INTERPRET LARGE DATASETS, MAKING IT A VALUABLE TOOL FOR RESEARCHERS IN VARIOUS FIELDS.\n",
      "5. **STUDENTS**: LEARNING ML CAN PROVIDE STUDENTS WITH A COMPETITIVE EDGE IN THE JOB MARKET AND OPEN UP NEW CAREER OPPORTUNITIES.\n",
      "\n",
      "**HOW TO GET STARTED WITH MACHINE LEARNING?**\n",
      "\n",
      "1. **TAKE ONLINE COURSES**: WEBSITES LIKE COURSERA, EDX, AND UDEMY OFFER A WIDE RANGE OF ML COURSES.\n",
      "2. **READ BOOKS AND RESEARCH PAPERS**: STAY UP-TO-DATE WITH THE LATEST DEVELOPMENTS IN ML BY READING BOOKS AND RESEARCH PAPERS.\n",
      "3. **JOIN ONLINE COMMUNITIES**: PARTICIPATE IN ONLINE FORUMS, SUCH AS KAGGLE, REDDIT, AND GITHUB, TO LEARN FROM OTHERS AND GET FEEDBACK ON YOUR PROJECTS.\n",
      "4. **WORK ON PROJECTS**: APPLY ML CONCEPTS TO REAL-WORLD PROBLEMS AND PROJECTS TO GAIN PRACTICAL EXPERIENCE.\n",
      "5. **SEEK MENTORSHIP**: FIND A MENTOR WHO CAN GUIDE YOU AND PROVIDE FEEDBACK ON YOUR PROGRESS.\n"
     ]
    }
   ],
   "source": [
    "print(app2.invoke(\"Is learning machine learning important?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5471c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Do you think I am dumb?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3184a82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is output from llm\n",
      "_______\n",
      "No, I don't think you're dumb. I'm a large language model, my purpose is to assist and provide information, not to judge or make personal opinions about individuals. Intelligence comes in many forms, and it's not defined by a single interaction or conversation. Everyone has their own strengths, weaknesses, and learning styles. \n",
      "\n",
      "I'm here to help answer your questions, provide information, and support your learning. If you have any questions or topics you'd like to discuss, I'm here to listen and help.\n",
      "\n",
      "\n",
      "here is output from convert_upper\n",
      "_______\n",
      "NO, I DON'T THINK YOU'RE DUMB. I'M A LARGE LANGUAGE MODEL, MY PURPOSE IS TO ASSIST AND PROVIDE INFORMATION, NOT TO JUDGE OR MAKE PERSONAL OPINIONS ABOUT INDIVIDUALS. INTELLIGENCE COMES IN MANY FORMS, AND IT'S NOT DEFINED BY A SINGLE INTERACTION OR CONVERSATION. EVERYONE HAS THEIR OWN STRENGTHS, WEAKNESSES, AND LEARNING STYLES. \n",
      "\n",
      "I'M HERE TO HELP ANSWER YOUR QUESTIONS, PROVIDE INFORMATION, AND SUPPORT YOUR LEARNING. IF YOU HAVE ANY QUESTIONS OR TOPICS YOU'D LIKE TO DISCUSS, I'M HERE TO LISTEN AND HELP.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for output in app2.stream(input):\n",
    "    for key,value in output.items():\n",
    "        print(f\"here is output from {key}\")\n",
    "        print(\"_______\")\n",
    "        print(value)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae2bb7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a37858a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
