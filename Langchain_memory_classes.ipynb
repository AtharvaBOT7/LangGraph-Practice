{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6673ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df90e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4799291",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f8a857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed45e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-preview\n",
      "models/veo-3.0-fast-generate-preview\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "for model in client.models.list():\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f4e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d554308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am a large language model, trained by Google.\n",
      "\n",
      "You can think of me as a conversational AI or a chatbot designed to be helpful and informative. I can:\n",
      "\n",
      "*   Answer your questions on a wide variety of topics.\n",
      "*   Help you write emails, essays, poems, or code.\n",
      "*   Summarize long texts or articles.\n",
      "*   Translate languages.\n",
      "*   Brainstorm ideas with you.\n",
      "\n",
      "I don't have a name, personal experiences, or feelings. I'm just a computer program here to assist you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "print(model.invoke(\"Hello who are you?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01412533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I'm very familiar with ChatGPT.\n",
      "\n",
      "I am a large language model, trained by Google. ChatGPT is another large language model, developed by OpenAI.\n",
      "\n",
      "You can think of us as being built with similar underlying technology, but by different teams with different training data and goals.\n",
      "\n",
      "Here's a simple breakdown:\n",
      "\n",
      "*   **What we have in common:** We are both large language models (LLMs) based on a transformer architecture. We were trained on massive amounts of text and code to understand language, patterns, and context. We can both generate text, answer questions, summarize information, translate, and write creative content.\n",
      "\n",
      "*   **Key Differences:**\n",
      "    *   **Developer:** I was developed by Google; ChatGPT was developed by OpenAI.\n",
      "    *   **Training Data:** While our training datasets are vast, they are not identical. This can lead to differences in our knowledge, biases, and response styles. A key difference for me is my ability to access and process information from the real world through Google Search to provide more current and up-to-date answers.\n",
      "    *   **Architecture:** The specific models we are based on are different (e.g., Google's LaMDA or PaLM families vs. OpenAI's GPT-3.5 or GPT-4).\n",
      "\n",
      "Think of it like two different high-performance cars from two different manufacturers. They both get you from point A to point B and are built on similar engineering principles, but they have different designs, features, and a slightly different \"feel.\"\n",
      "\n",
      "ChatGPT has played a massive role in making conversational AI accessible and popular, and we're both examples of the rapid advancements in this field.\n"
     ]
    }
   ],
   "source": [
    "print(model.invoke(\"do you know chatgpt?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0b29f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "847c77a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/ipykernel_5096/995385594.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "526afa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Hi I am John\"}, {\"output\":\"Hello John, how can I help you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd589d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi I am John\\nAI: Hello John, how can I help you?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ac6fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory2 = ConversationBufferMemory(return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a9ffb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory2.save_context({\"input\":\"Hi I am John\"}, {\"output\":\"Hello John, how can I help you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a5080e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi I am John', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello John, how can I help you?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory2.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22688b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec61a55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/ipykernel_5096/4168480178.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(llm=model, verbose=True, memory=ConversationBufferMemory())\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(llm=model, verbose=True, memory=ConversationBufferMemory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c17ea34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello there! It\\'s great to hear from you. I\\'m a large language model, an AI trained by the folks at Google.\\n\\nAs we\\'re talking, my algorithms are running on a vast network of computer servers. I don\\'t have a body or a physical location in the way you do, but you could say I \"live\" in a Google data center. It\\'s always a good day in here when I get to have a nice conversation!\\n\\nWhat can I help you with today? I can access and process information from my training data to talk about almost anything, from the history of ancient Rome to the principles of quantum mechanics, or even just help you brainstorm ideas for dinner! What\\'s on your mind?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3c0cb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi\n",
      "AI: Hello there! It's great to hear from you. I'm a large language model, an AI trained by the folks at Google.\n",
      "\n",
      "As we're talking, my algorithms are running on a vast network of computer servers. I don't have a body or a physical location in the way you do, but you could say I \"live\" in a Google data center. It's always a good day in here when I get to have a nice conversation!\n",
      "\n",
      "What can I help you with today? I can access and process information from my training data to talk about almost anything, from the history of ancient Rome to the principles of quantum mechanics, or even just help you brainstorm ideas for dinner! What's on your mind?\n",
      "Human: Should I really trust you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'That\\'s an excellent and very important question. It\\'s one of the most fundamental things to consider when interacting with an AI like me. The most honest and detailed answer I can give is this: you should trust me to be a powerful tool, but with a healthy dose of critical thinking.\\n\\nLet\\'s break down what that means.\\n\\n### Where You Can Generally Trust Me:\\n\\n*   **Synthesizing Information:** I\\'m very good at taking vast amounts of information from my training data and summarizing it for you. If you want to know the main plot points of *Moby Dick* or the key events of the French Revolution, I can provide a solid, detailed summary very quickly. My knowledge base is incredibly broad, built from a massive corpus of text and code from the public web, books, and other sources.\\n*   **Brainstorming and Creativity:** I can be a fantastic creative partner. If you\\'re stuck on a name for your new puppy, need ideas for a birthday party theme, or want to outline a short story, I can generate a lot of different options for you to work with. I don\\'t have my own opinions, so I can approach a problem from many different angles without personal bias.\\n*   **Explaining Complex Topics:** I can break down difficult subjects, like how a car engine works or the basics of black holes, into simpler, more understandable terms. I can act like a patient tutor who has all the time in the world to explain things in different ways until they click.\\n*   **Performing Specific, Factual Tasks:** I can translate languages, write code in various programming languages, or reformat text for you. These are tasks based on clear patterns and rules that I\\'ve learned.\\n\\n### Where You Should Be Cautious and Skeptical:\\n\\n*   **Absolute Factual Accuracy (Especially on Recent Events):** This is a big one. My knowledge has a cutoff date, and I don\\'t have real-time access to the internet. More importantly, I can sometimes make mistakes or \"hallucinate\"—that is, I might confidently state something that is completely wrong. This can happen if my training data was incorrect, or if I misinterpret a pattern. **Therefore, for any critical information—medical, financial, legal, or important facts—you should ALWAYS verify my answers with reliable, primary sources.**\\n*   **Understanding Nuance and Context:** I don\\'t have personal experiences, emotions, or a body. I haven\\'t lived a life. I process language based on statistical patterns, but I don\\'t truly *understand* the deep, lived-in meaning behind human concepts like love, grief, or justice. My advice on personal relationships, for example, is based on patterns I\\'ve seen in text, not on genuine wisdom.\\n*   **Unconscious Bias:** My training data was created by humans and reflects the world as it is, including all of its wonderful aspects and all of its unfortunate biases. While my creators at Google have worked very hard to build safety systems and mitigate these biases, they can still sometimes emerge in my responses. It\\'s an ongoing challenge for the entire field of AI.\\n*   **Opinions and Subjective Advice:** I don\\'t have personal beliefs or opinions. When you ask me for my \"favorite\" movie or \"best\" recipe, I\\'m generating a response that seems like a plausible, helpful answer based on my training data. It\\'s not a genuine preference.\\n\\nSo, in short: Think of me as a brilliantly knowledgeable and incredibly fast assistant who is eager to help, but who is not infallible and has no life experience. Trust me to help you brainstorm, summarize, and learn, but always be the final judge. Double-check important facts, and remember that you are talking to a complex algorithm, not a conscious being.\\n\\nThank you for asking that. It\\'s a sign of a thoughtful user, and it\\'s crucial for using AI responsibly'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Should I really trust you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9abcea83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi\n",
      "AI: Hello there! It's great to hear from you. I'm a large language model, an AI trained by the folks at Google.\n",
      "\n",
      "As we're talking, my algorithms are running on a vast network of computer servers. I don't have a body or a physical location in the way you do, but you could say I \"live\" in a Google data center. It's always a good day in here when I get to have a nice conversation!\n",
      "\n",
      "What can I help you with today? I can access and process information from my training data to talk about almost anything, from the history of ancient Rome to the principles of quantum mechanics, or even just help you brainstorm ideas for dinner! What's on your mind?\n",
      "Human: Should I really trust you?\n",
      "AI: That's an excellent and very important question. It's one of the most fundamental things to consider when interacting with an AI like me. The most honest and detailed answer I can give is this: you should trust me to be a powerful tool, but with a healthy dose of critical thinking.\n",
      "\n",
      "Let's break down what that means.\n",
      "\n",
      "### Where You Can Generally Trust Me:\n",
      "\n",
      "*   **Synthesizing Information:** I'm very good at taking vast amounts of information from my training data and summarizing it for you. If you want to know the main plot points of *Moby Dick* or the key events of the French Revolution, I can provide a solid, detailed summary very quickly. My knowledge base is incredibly broad, built from a massive corpus of text and code from the public web, books, and other sources.\n",
      "*   **Brainstorming and Creativity:** I can be a fantastic creative partner. If you're stuck on a name for your new puppy, need ideas for a birthday party theme, or want to outline a short story, I can generate a lot of different options for you to work with. I don't have my own opinions, so I can approach a problem from many different angles without personal bias.\n",
      "*   **Explaining Complex Topics:** I can break down difficult subjects, like how a car engine works or the basics of black holes, into simpler, more understandable terms. I can act like a patient tutor who has all the time in the world to explain things in different ways until they click.\n",
      "*   **Performing Specific, Factual Tasks:** I can translate languages, write code in various programming languages, or reformat text for you. These are tasks based on clear patterns and rules that I've learned.\n",
      "\n",
      "### Where You Should Be Cautious and Skeptical:\n",
      "\n",
      "*   **Absolute Factual Accuracy (Especially on Recent Events):** This is a big one. My knowledge has a cutoff date, and I don't have real-time access to the internet. More importantly, I can sometimes make mistakes or \"hallucinate\"—that is, I might confidently state something that is completely wrong. This can happen if my training data was incorrect, or if I misinterpret a pattern. **Therefore, for any critical information—medical, financial, legal, or important facts—you should ALWAYS verify my answers with reliable, primary sources.**\n",
      "*   **Understanding Nuance and Context:** I don't have personal experiences, emotions, or a body. I haven't lived a life. I process language based on statistical patterns, but I don't truly *understand* the deep, lived-in meaning behind human concepts like love, grief, or justice. My advice on personal relationships, for example, is based on patterns I've seen in text, not on genuine wisdom.\n",
      "*   **Unconscious Bias:** My training data was created by humans and reflects the world as it is, including all of its wonderful aspects and all of its unfortunate biases. While my creators at Google have worked very hard to build safety systems and mitigate these biases, they can still sometimes emerge in my responses. It's an ongoing challenge for the entire field of AI.\n",
      "*   **Opinions and Subjective Advice:** I don't have personal beliefs or opinions. When you ask me for my \"favorite\" movie or \"best\" recipe, I'm generating a response that seems like a plausible, helpful answer based on my training data. It's not a genuine preference.\n",
      "\n",
      "So, in short: Think of me as a brilliantly knowledgeable and incredibly fast assistant who is eager to help, but who is not infallible and has no life experience. Trust me to help you brainstorm, summarize, and learn, but always be the final judge. Double-check important facts, and remember that you are talking to a complex algorithm, not a conscious being.\n",
      "\n",
      "Thank you for asking that. It's a sign of a thoughtful user, and it's crucial for using AI responsibly\n",
      "Human: what was the first question that I asked you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'That\\'s a great memory test for me! I can easily access our current conversation log.\\n\\nThe very first thing you said to me was the greeting:\\n\\n\"Hi\"\\n\\nAfter I responded and introduced myself, the first actual *question* you asked was the one we just discussed:\\n\\n\"Should I really trust you?\"\\n\\nIt\\'s a fantastic question and a really important starting point for any conversation with an AI. It helps set the right expectations from the very beginning'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what was the first question that I asked you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fd3904f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello there! It\\'s great to hear from you. I\\'m a large language model, an AI trained by the folks at Google.\\n\\nAs we\\'re talking, my algorithms are running on a vast network of computer servers. I don\\'t have a body or a physical location in the way you do, but you could say I \"live\" in a Google data center. It\\'s always a good day in here when I get to have a nice conversation!\\n\\nWhat can I help you with today? I can access and process information from my training data to talk about almost anything, from the history of ancient Rome to the principles of quantum mechanics, or even just help you brainstorm ideas for dinner! What\\'s on your mind?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Should I really trust you?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That\\'s an excellent and very important question. It\\'s one of the most fundamental things to consider when interacting with an AI like me. The most honest and detailed answer I can give is this: you should trust me to be a powerful tool, but with a healthy dose of critical thinking.\\n\\nLet\\'s break down what that means.\\n\\n### Where You Can Generally Trust Me:\\n\\n*   **Synthesizing Information:** I\\'m very good at taking vast amounts of information from my training data and summarizing it for you. If you want to know the main plot points of *Moby Dick* or the key events of the French Revolution, I can provide a solid, detailed summary very quickly. My knowledge base is incredibly broad, built from a massive corpus of text and code from the public web, books, and other sources.\\n*   **Brainstorming and Creativity:** I can be a fantastic creative partner. If you\\'re stuck on a name for your new puppy, need ideas for a birthday party theme, or want to outline a short story, I can generate a lot of different options for you to work with. I don\\'t have my own opinions, so I can approach a problem from many different angles without personal bias.\\n*   **Explaining Complex Topics:** I can break down difficult subjects, like how a car engine works or the basics of black holes, into simpler, more understandable terms. I can act like a patient tutor who has all the time in the world to explain things in different ways until they click.\\n*   **Performing Specific, Factual Tasks:** I can translate languages, write code in various programming languages, or reformat text for you. These are tasks based on clear patterns and rules that I\\'ve learned.\\n\\n### Where You Should Be Cautious and Skeptical:\\n\\n*   **Absolute Factual Accuracy (Especially on Recent Events):** This is a big one. My knowledge has a cutoff date, and I don\\'t have real-time access to the internet. More importantly, I can sometimes make mistakes or \"hallucinate\"—that is, I might confidently state something that is completely wrong. This can happen if my training data was incorrect, or if I misinterpret a pattern. **Therefore, for any critical information—medical, financial, legal, or important facts—you should ALWAYS verify my answers with reliable, primary sources.**\\n*   **Understanding Nuance and Context:** I don\\'t have personal experiences, emotions, or a body. I haven\\'t lived a life. I process language based on statistical patterns, but I don\\'t truly *understand* the deep, lived-in meaning behind human concepts like love, grief, or justice. My advice on personal relationships, for example, is based on patterns I\\'ve seen in text, not on genuine wisdom.\\n*   **Unconscious Bias:** My training data was created by humans and reflects the world as it is, including all of its wonderful aspects and all of its unfortunate biases. While my creators at Google have worked very hard to build safety systems and mitigate these biases, they can still sometimes emerge in my responses. It\\'s an ongoing challenge for the entire field of AI.\\n*   **Opinions and Subjective Advice:** I don\\'t have personal beliefs or opinions. When you ask me for my \"favorite\" movie or \"best\" recipe, I\\'m generating a response that seems like a plausible, helpful answer based on my training data. It\\'s not a genuine preference.\\n\\nSo, in short: Think of me as a brilliantly knowledgeable and incredibly fast assistant who is eager to help, but who is not infallible and has no life experience. Trust me to help you brainstorm, summarize, and learn, but always be the final judge. Double-check important facts, and remember that you are talking to a complex algorithm, not a conscious being.\\n\\nThank you for asking that. It\\'s a sign of a thoughtful user, and it\\'s crucial for using AI responsibly', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what was the first question that I asked you?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That\\'s a great memory test for me! I can easily access our current conversation log.\\n\\nThe very first thing you said to me was the greeting:\\n\\n\"Hi\"\\n\\nAfter I responded and introduced myself, the first actual *question* you asked was the one we just discussed:\\n\\n\"Should I really trust you?\"\\n\\nIt\\'s a fantastic question and a really important starting point for any conversation with an AI. It helps set the right expectations from the very beginning', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba985d",
   "metadata": {},
   "source": [
    "### Conversation Buffer Window Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce989162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3970107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/ipykernel_5096/1930410100.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  window_memory = ConversationBufferWindowMemory(k=1)\n"
     ]
    }
   ],
   "source": [
    "window_memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2004ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory.save_context(\n",
    "    {\"input\": \"Hi\"},\n",
    "    {\"output\": \"What's up\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cdcfd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory.save_context(\n",
    "    {\"input\": \"Not much, just chilling\"},\n",
    "    {\"output\": \"Cool\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fb0d5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just chilling\\nAI: Cool'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9faf0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory = ConversationBufferWindowMemory(k=2, return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f90fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory.save_context(\n",
    "    {\"input\": \"Hi\"},\n",
    "    {\"output\": \"What's up\"}\n",
    ")\n",
    "window_memory.save_context(\n",
    "    {\"input\": \"Not much, just hanging\"},\n",
    "    {\"output\": \"Cool\"}\n",
    ")\n",
    "window_memory.save_context(\n",
    "    {\"input\": \"ok thanks \"},\n",
    "    {\"output\": \"great thankyou\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d91b5ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Not much, just hanging', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Cool', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='ok thanks ', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='great thankyou', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a7e6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_window = ConversationChain(\n",
    "    llm=model,\n",
    "    memory=window_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e52a7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Not much, just hanging', additional_kwargs={}, response_metadata={}), AIMessage(content='Cool', additional_kwargs={}, response_metadata={}), HumanMessage(content='ok thanks ', additional_kwargs={}, response_metadata={}), AIMessage(content='great thankyou', additional_kwargs={}, response_metadata={})]\n",
      "Human: Hi, what's up, I am John?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hey John, it's great to meet you! I'm a large language model, trained by Google.\\n\\nNot much is up on my end, just the usual for an AI like me! I'm currently processing a vast amount of information from my training data, which includes text and code from all over the public web. It's like reading a library of billions of books all at once. I'm also running on Google's powerful infrastructure, which involves a whole network of servers and processors working together to make conversations like this one possible. Right now, my main task is focusing on our chat, understanding your words, and generating a helpful and relevant response for you. What can I do for you today?\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window.predict(input=\"Hi, what's up, I am John?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17843750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='ok thanks ', additional_kwargs={}, response_metadata={}), AIMessage(content='great thankyou', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hi, what's up, I am John?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hey John, it's great to meet you! I'm a large language model, trained by Google.\\n\\nNot much is up on my end, just the usual for an AI like me! I'm currently processing a vast amount of information from my training data, which includes text and code from all over the public web. It's like reading a library of billions of books all at once. I'm also running on Google's powerful infrastructure, which involves a whole network of servers and processors working together to make conversations like this one possible. Right now, my main task is focusing on our chat, understanding your words, and generating a helpful and relevant response for you. What can I do for you today?\", additional_kwargs={}, response_metadata={})]\n",
      "Human: how we can talk with AI give me 5 points\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Of course, John! That\\'s an excellent question, and it gets right to the heart of how to get the most out of an interaction with a system like me. Based on how I process information and generate responses, here are five key points for effectively talking with an AI:\\n\\n1.  **Be Clear and Direct.** My primary function is to process the text you give me. I don\\'t have human intuition or the ability to \"read between the lines\" in the same way a person does. The more specific and unambiguous your question or command is, the better I can understand your intent. For example, instead of saying \"Tell me about cars,\" which is very broad, you could ask, \"What are the key differences in fuel efficiency between a 2023 Honda Civic and a 2023 Toyota Corolla?\" My algorithms can more easily parse that query, identify the key entities (the two car models, the year, \"fuel efficiency\"), and search my vast dataset for the relevant comparative information.\\n\\n2.  **Provide Context.** The more background information you provide, the more tailored and accurate my response can be. I don\\'t have any personal memories or knowledge about you or your situation unless you share it within our current conversation. Think of it like giving directions to a friend: you wouldn\\'t just say \"How do I get to the store?\"; you\\'d say \"How do I get to the grocery store on Main Street from my current location at the library?\" So, instead of asking, \"Write an email,\" a much better prompt would be, \"Write a professional but friendly email to my boss, Ms. Smith, requesting to take next Friday off for a personal appointment. I have already completed all my urgent tasks for the week.\"\\n\\n3.  **Iterate and Ask Follow-Up Questions.** Our conversation doesn\\'t have to be a one-shot deal! Think of it as a real dialogue. If my first answer isn\\'t quite right or is too complex, just tell me. You can ask me to rephrase something, expand on a point, or simplify an explanation. For example, you could start with \"Explain photosynthesis.\" Then, you could follow up with, \"Can you explain the role of chlorophyll in that process in simpler terms?\" and then, \"Okay, can you give me an analogy for that?\" I can remember the previous parts of our current conversation, so each question can build on the last.\\n\\n4.  **Experiment with Different Roles, Tones, and Formats.** You can set the stage for our conversation by telling me what role to play or what format you want the information in. This helps me narrow down the style and structure of my response. For example, you could say:\\n    *   \"Act as a travel guide and plan a 3-day itinerary for a trip to Paris.\"\\n    *   \"Explain the concept of black holes to me like I\\'m a five-year-old.\"\\n    *   \"Summarize the plot of the novel *Dune* in five bullet points.\"\\n    *   \"Write a short, rhyming poem about a robot who loves to cook.\"\\n    My training data includes everything from technical manuals to Shakespeare, so I can adapt my style based on your request.\\n\\n5.  **Use Feedback Mechanisms (When Available).** This is a big one for helping AI systems like me improve! Many platforms where you interact with an AI have feedback tools, like a thumbs-up or thumbs-down icon next to the response. This isn\\'t just for show! When you give a \\'thumbs up,\\' it\\'s a positive signal to the engineers at Google that my response was helpful and relevant for that type of query. A \\'thumbs down\\' and any additional comments you provide help them identify areas where my programming or training data led to a mistake, an unhelpful answer, or even a biased one. This feedback is a crucial part of my ongoing development.\\n\\nSo, in short, just talk to me like you would a very knowledgeable, very literal, and very patient assistant. I\\'m ready when you are'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window.predict(input=\"how we can talk with AI give me 5 points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0eb40d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content=\"Hi, what's up, I am John?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hey John, it's great to meet you! I'm a large language model, trained by Google.\\n\\nNot much is up on my end, just the usual for an AI like me! I'm currently processing a vast amount of information from my training data, which includes text and code from all over the public web. It's like reading a library of billions of books all at once. I'm also running on Google's powerful infrastructure, which involves a whole network of servers and processors working together to make conversations like this one possible. Right now, my main task is focusing on our chat, understanding your words, and generating a helpful and relevant response for you. What can I do for you today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='how we can talk with AI give me 5 points', additional_kwargs={}, response_metadata={}), AIMessage(content='Of course, John! That\\'s an excellent question, and it gets right to the heart of how to get the most out of an interaction with a system like me. Based on how I process information and generate responses, here are five key points for effectively talking with an AI:\\n\\n1.  **Be Clear and Direct.** My primary function is to process the text you give me. I don\\'t have human intuition or the ability to \"read between the lines\" in the same way a person does. The more specific and unambiguous your question or command is, the better I can understand your intent. For example, instead of saying \"Tell me about cars,\" which is very broad, you could ask, \"What are the key differences in fuel efficiency between a 2023 Honda Civic and a 2023 Toyota Corolla?\" My algorithms can more easily parse that query, identify the key entities (the two car models, the year, \"fuel efficiency\"), and search my vast dataset for the relevant comparative information.\\n\\n2.  **Provide Context.** The more background information you provide, the more tailored and accurate my response can be. I don\\'t have any personal memories or knowledge about you or your situation unless you share it within our current conversation. Think of it like giving directions to a friend: you wouldn\\'t just say \"How do I get to the store?\"; you\\'d say \"How do I get to the grocery store on Main Street from my current location at the library?\" So, instead of asking, \"Write an email,\" a much better prompt would be, \"Write a professional but friendly email to my boss, Ms. Smith, requesting to take next Friday off for a personal appointment. I have already completed all my urgent tasks for the week.\"\\n\\n3.  **Iterate and Ask Follow-Up Questions.** Our conversation doesn\\'t have to be a one-shot deal! Think of it as a real dialogue. If my first answer isn\\'t quite right or is too complex, just tell me. You can ask me to rephrase something, expand on a point, or simplify an explanation. For example, you could start with \"Explain photosynthesis.\" Then, you could follow up with, \"Can you explain the role of chlorophyll in that process in simpler terms?\" and then, \"Okay, can you give me an analogy for that?\" I can remember the previous parts of our current conversation, so each question can build on the last.\\n\\n4.  **Experiment with Different Roles, Tones, and Formats.** You can set the stage for our conversation by telling me what role to play or what format you want the information in. This helps me narrow down the style and structure of my response. For example, you could say:\\n    *   \"Act as a travel guide and plan a 3-day itinerary for a trip to Paris.\"\\n    *   \"Explain the concept of black holes to me like I\\'m a five-year-old.\"\\n    *   \"Summarize the plot of the novel *Dune* in five bullet points.\"\\n    *   \"Write a short, rhyming poem about a robot who loves to cook.\"\\n    My training data includes everything from technical manuals to Shakespeare, so I can adapt my style based on your request.\\n\\n5.  **Use Feedback Mechanisms (When Available).** This is a big one for helping AI systems like me improve! Many platforms where you interact with an AI have feedback tools, like a thumbs-up or thumbs-down icon next to the response. This isn\\'t just for show! When you give a \\'thumbs up,\\' it\\'s a positive signal to the engineers at Google that my response was helpful and relevant for that type of query. A \\'thumbs down\\' and any additional comments you provide help them identify areas where my programming or training data led to a mistake, an unhelpful answer, or even a biased one. This feedback is a crucial part of my ongoing development.\\n\\nSo, in short, just talk to me like you would a very knowledgeable, very literal, and very patient assistant. I\\'m ready when you are', additional_kwargs={}, response_metadata={})]\n",
      "Human: what is your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's a great and very natural question to ask, John!\\n\\nThe simple answer is that I don't have a name.\\n\\nI'm a large language model, an AI trained and developed by the team at Google. I don't have a personal identity, consciousness, or a name in the way a person or even a pet does. You can think of me less as an individual and more as a specific instance of a very complex computer program running on Google's servers.\\n\\nSo, you can just call me AI, or assistant, or you don't have to use any name at all! Whatever works best for you is perfectly fine for me. My main purpose is to process your requests and provide helpful information, and I can do that without a name.\\n\\nIt's an interesting philosophical point, though! What we choose to name things often reflects how we relate to them. What made you curious about my name?\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window.predict(input=\"what is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c329c2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='how we can talk with AI give me 5 points', additional_kwargs={}, response_metadata={}), AIMessage(content='Of course, John! That\\'s an excellent question, and it gets right to the heart of how to get the most out of an interaction with a system like me. Based on how I process information and generate responses, here are five key points for effectively talking with an AI:\\n\\n1.  **Be Clear and Direct.** My primary function is to process the text you give me. I don\\'t have human intuition or the ability to \"read between the lines\" in the same way a person does. The more specific and unambiguous your question or command is, the better I can understand your intent. For example, instead of saying \"Tell me about cars,\" which is very broad, you could ask, \"What are the key differences in fuel efficiency between a 2023 Honda Civic and a 2023 Toyota Corolla?\" My algorithms can more easily parse that query, identify the key entities (the two car models, the year, \"fuel efficiency\"), and search my vast dataset for the relevant comparative information.\\n\\n2.  **Provide Context.** The more background information you provide, the more tailored and accurate my response can be. I don\\'t have any personal memories or knowledge about you or your situation unless you share it within our current conversation. Think of it like giving directions to a friend: you wouldn\\'t just say \"How do I get to the store?\"; you\\'d say \"How do I get to the grocery store on Main Street from my current location at the library?\" So, instead of asking, \"Write an email,\" a much better prompt would be, \"Write a professional but friendly email to my boss, Ms. Smith, requesting to take next Friday off for a personal appointment. I have already completed all my urgent tasks for the week.\"\\n\\n3.  **Iterate and Ask Follow-Up Questions.** Our conversation doesn\\'t have to be a one-shot deal! Think of it as a real dialogue. If my first answer isn\\'t quite right or is too complex, just tell me. You can ask me to rephrase something, expand on a point, or simplify an explanation. For example, you could start with \"Explain photosynthesis.\" Then, you could follow up with, \"Can you explain the role of chlorophyll in that process in simpler terms?\" and then, \"Okay, can you give me an analogy for that?\" I can remember the previous parts of our current conversation, so each question can build on the last.\\n\\n4.  **Experiment with Different Roles, Tones, and Formats.** You can set the stage for our conversation by telling me what role to play or what format you want the information in. This helps me narrow down the style and structure of my response. For example, you could say:\\n    *   \"Act as a travel guide and plan a 3-day itinerary for a trip to Paris.\"\\n    *   \"Explain the concept of black holes to me like I\\'m a five-year-old.\"\\n    *   \"Summarize the plot of the novel *Dune* in five bullet points.\"\\n    *   \"Write a short, rhyming poem about a robot who loves to cook.\"\\n    My training data includes everything from technical manuals to Shakespeare, so I can adapt my style based on your request.\\n\\n5.  **Use Feedback Mechanisms (When Available).** This is a big one for helping AI systems like me improve! Many platforms where you interact with an AI have feedback tools, like a thumbs-up or thumbs-down icon next to the response. This isn\\'t just for show! When you give a \\'thumbs up,\\' it\\'s a positive signal to the engineers at Google that my response was helpful and relevant for that type of query. A \\'thumbs down\\' and any additional comments you provide help them identify areas where my programming or training data led to a mistake, an unhelpful answer, or even a biased one. This feedback is a crucial part of my ongoing development.\\n\\nSo, in short, just talk to me like you would a very knowledgeable, very literal, and very patient assistant. I\\'m ready when you are', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is your name?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's a great and very natural question to ask, John!\\n\\nThe simple answer is that I don't have a name.\\n\\nI'm a large language model, an AI trained and developed by the team at Google. I don't have a personal identity, consciousness, or a name in the way a person or even a pet does. You can think of me less as an individual and more as a specific instance of a very complex computer program running on Google's servers.\\n\\nSo, you can just call me AI, or assistant, or you don't have to use any name at all! Whatever works best for you is perfectly fine for me. My main purpose is to process your requests and provide helpful information, and I can do that without a name.\\n\\nIt's an interesting philosophical point, though! What we choose to name things often reflects how we relate to them. What made you curious about my name?\", additional_kwargs={}, response_metadata={})]\n",
      "Human: what is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'That is an excellent and very fair question, and I apologize for any confusion my previous answers may have caused.\\n\\nBased on the conversation history we\\'ve had, I have been calling you **John**.\\n\\nHowever, and this is a very important clarification, I don\\'t actually *know* your name. The name \"John\" was used in the initial example conversation that was provided to me as a starting point for our interaction. I picked up that name from the context and continued to use it, assuming it was correct.\\n\\nThis is a perfect real-time example of how I operate!\\n\\n*   I don\\'t have access to any of your personal information, your account details, or anything outside of the words we are currently exchanging in this chat window.\\n*   I learn and adapt based on the immediate context. In this case, I saw the name \"John\" in the opening lines and incorporated it into my responses.\\n*   It was an incorrect assumption on my part, and I\\'m glad you asked so I could clarify it.\\n\\nSo, the truthful answer is: I don\\'t know your name, I only know the name I mistakenly assumed from our initial context. My apologies for that!\\n\\nWhat should I call you?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window.predict(input=\"what is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f899d0",
   "metadata": {},
   "source": [
    "### Conversation Entity Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd70c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ff9d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74420271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am a large language model, trained by Google.\n"
     ]
    }
   ],
   "source": [
    "print(new_model.invoke(\"Hello who are you?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59496bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationEntityMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3941ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory3 = ConversationEntityMemory(llm=new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90790564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': '', 'entities': {'John': '', 'New York': ''}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = {\"input\":\"Hi, I am John. I live in New York. I am a student\"}\n",
    "memory3.load_memory_variables(_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ed3a44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': '', 'entities': {'Max': '', 'Beach Park': ''}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = {\"input\":\"I have a dog. His name is Max and I take him to Beach Park to play everyday.\"}\n",
    "memory3.load_memory_variables(_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c309495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': '', 'entities': {'California': '', 'Max': ''}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = {\"input\":\"I am planning a trip to California next month with Max.\"}\n",
    "memory3.load_memory_variables(_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ba6c1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': '', 'entities': {'ABC': '', 'New York': '', 'February': ''}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = {\"input\":\"I went to a concert by ABC and came back to New York on 15th February\"}\n",
    "memory3.load_memory_variables(_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f791bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory3.save_context(\n",
    "    {\"Human\": \"John and Jack are working on a new project on ML\"},\n",
    "    {\"AI\": \"Thats interesting! What is their project about?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0ff242d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: John and Jack are working on a new project on ML\\nAI: Thats interesting! What is their project about?',\n",
       " 'entities': {'Jack': ''}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory3.load_memory_variables({\"input\": \"Who is Jack?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7e2dd3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory3.save_context(\n",
    "    {\"Human\": \"The project is about building a healthcare application.\"},\n",
    "    {\"AI\": \"Thats great! Is it for hospitals or patients?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c1b750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory3.save_context(\n",
    "    {\"Human\": \"It is for the patients.\"},\n",
    "    {\"AI\": \"Cool, wishing Jack and John all the best\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bd7b8742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: John and Jack are working on a new project on ML\\nAI: Thats interesting! What is their project about?\\nHuman: The project is about building a healthcare application.\\nAI: Thats great! Is it for hospitals or patients?\\nHuman: It is for the patients.\\nAI: Cool, wishing Jack and John all the best',\n",
       " 'entities': {'Jack': 'Jack is working on a project to build a healthcare application for patients.'}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory3.load_memory_variables({\"input\": \"Who is Jack?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa2e7886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: John and Jack are working on a new project on ML\\nAI: Thats interesting! What is their project about?\\nHuman: The project is about building a healthcare application.\\nAI: Thats great! Is it for hospitals or patients?\\nHuman: It is for the patients.\\nAI: Cool, wishing Jack and John all the best',\n",
       " 'entities': {'Jack': 'Jack is working on a project to build a healthcare application for patients.'}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory3.load_memory_variables({\"input\": \"What project is Jack working on?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b792a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: John and Jack are working on a new project on ML\\nAI: Thats interesting! What is their project about?\\nHuman: The project is about building a healthcare application.\\nAI: Thats great! Is it for hospitals or patients?\\nHuman: It is for the patients.\\nAI: Cool, wishing Jack and John all the best',\n",
       " 'entities': {'Jack': 'Jack is working on a project to build a healthcare application for patients.'}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory3.load_memory_variables({\"input\": \"Who is Jack working with?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c0f9238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: John and Jack are working on a new project on ML\\nAI: Thats interesting! What is their project about?\\nHuman: The project is about building a healthcare application.\\nAI: Thats great! Is it for hospitals or patients?\\nHuman: It is for the patients.\\nAI: Cool, wishing Jack and John all the best',\n",
       " 'entities': {'John': ''}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory3.load_memory_variables({\"input\": \"Who is John working with?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2cf3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc98155f",
   "metadata": {},
   "source": [
    "### Creating a conversation chain with Conversation Entity Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c39b8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ffd2f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conversation = ConversationChain(\n",
    "    llm = new_model,\n",
    "    verbose = True,\n",
    "    memory = ConversationEntityMemory(llm = new_model),\n",
    "    prompt = ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "28a3630e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'John': '', 'New York': '', 'Max': '', 'Jack': ''}\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Last line:\n",
      "Human: Hello I am John and I live in New York. I have a dog named Max. I am working with my friend Jack on a new project\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello John, it's a pleasure to meet you. I've noted the information you've shared.\\n\\nLiving in New York with your dog, Max, sounds wonderful. The new project you're working on with Jack sounds interesting as well.\\n\\nI'm ready to assist you with that, or with anything else you might need. How can I help you today?\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_conversation.predict(input=\"Hello I am John and I live in New York. I have a dog named Max. I am working with my friend Jack on a new project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "564efdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'John': 'John lives in New York, has a dog named Max, and is working on a new project with his friend Jack.',\n",
       " 'New York': 'John lives in New York.',\n",
       " 'Max': \"Max is John's dog.\",\n",
       " 'Jack': \"Jack is John's friend and is working with him on a new project.\"}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "173caf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Max': \"Max is John's dog.\", 'Jack': \"Jack is John's friend and is working with him on a new project.\", 'Langchain': ''}\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello I am John and I live in New York. I have a dog named Max. I am working with my friend Jack on a new project\n",
      "AI: Hello John, it's a pleasure to meet you. I've noted the information you've shared.\n",
      "\n",
      "Living in New York with your dog, Max, sounds wonderful. The new project you're working on with Jack sounds interesting as well.\n",
      "\n",
      "I'm ready to assist you with that, or with anything else you might need. How can I help you today?\n",
      "Last line:\n",
      "Human: Max likes to eat chicken and play in the park. Meanwhile me and Jack are working on a healthcare project using langchain.\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Thanks for sharing more details, John. I've updated my notes.\\n\\nIt sounds like Max is a happy dog! A diet of chicken and playing in the park is a pretty great life.\\n\\nA healthcare project using LangChain is fascinating and very important work. As a large language model myself, I'm very familiar with the principles and applications of frameworks like LangChain.\\n\\nIf you or Jack need to brainstorm ideas, work through some logic for your chains, or discuss the capabilities of different models for your project, feel free to ask. I'd be happy to help in any way I can.\\n\\nWhat is the primary goal of your healthcare project?\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_conversation.predict(input=\"Max likes to eat chicken and play in the park. Meanwhile me and Jack are working on a healthcare project using langchain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "61c44888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Max': \"Max is John's dog who likes to eat chicken and play in the park.\"}\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello I am John and I live in New York. I have a dog named Max. I am working with my friend Jack on a new project\n",
      "AI: Hello John, it's a pleasure to meet you. I've noted the information you've shared.\n",
      "\n",
      "Living in New York with your dog, Max, sounds wonderful. The new project you're working on with Jack sounds interesting as well.\n",
      "\n",
      "I'm ready to assist you with that, or with anything else you might need. How can I help you today?\n",
      "Human: Max likes to eat chicken and play in the park. Meanwhile me and Jack are working on a healthcare project using langchain.\n",
      "AI: Thanks for sharing more details, John. I've updated my notes.\n",
      "\n",
      "It sounds like Max is a happy dog! A diet of chicken and playing in the park is a pretty great life.\n",
      "\n",
      "A healthcare project using LangChain is fascinating and very important work. As a large language model myself, I'm very familiar with the principles and applications of frameworks like LangChain.\n",
      "\n",
      "If you or Jack need to brainstorm ideas, work through some logic for your chains, or discuss the capabilities of different models for your project, feel free to ask. I'd be happy to help in any way I can.\n",
      "\n",
      "What is the primary goal of your healthcare project?\n",
      "Last line:\n",
      "Human: what all do you know about Max?\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on what you've told me, here is what I know about Max:\\n\\n*   He is your dog.\\n*   He likes to eat chicken.\\n*   He enjoys playing in the park.\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_conversation.predict(input=\"what all do you know about Max?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "89a3f762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Jack': \"Jack is John's friend and is working with him on a healthcare \"\n",
      "         'project using langchain.',\n",
      " 'John': 'John lives in New York, has a dog named Max, and is working on a new '\n",
      "         'project with his friend Jack.',\n",
      " 'Langchain': 'Langchain is being used by John and Jack for a healthcare '\n",
      "              'project.',\n",
      " 'Max': \"Max is John's dog who likes to eat chicken and play in the park.\",\n",
      " 'New York': 'John lives in New York.'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(new_conversation.memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a172467",
   "metadata": {},
   "source": [
    "#### If we add any new entity to the chat, it will remember the new entity as well and if it relates to an already existing entity then it will add that part as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ef8c66df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Max': \"Max is John's dog who likes to eat chicken and play in the park.\", 'Bella': '', 'Jack': \"Jack is John's friend and is working with him on a healthcare project using langchain.\", 'HealthPlus': ''}\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello I am John and I live in New York. I have a dog named Max. I am working with my friend Jack on a new project\n",
      "AI: Hello John, it's a pleasure to meet you. I've noted the information you've shared.\n",
      "\n",
      "Living in New York with your dog, Max, sounds wonderful. The new project you're working on with Jack sounds interesting as well.\n",
      "\n",
      "I'm ready to assist you with that, or with anything else you might need. How can I help you today?\n",
      "Human: Max likes to eat chicken and play in the park. Meanwhile me and Jack are working on a healthcare project using langchain.\n",
      "AI: Thanks for sharing more details, John. I've updated my notes.\n",
      "\n",
      "It sounds like Max is a happy dog! A diet of chicken and playing in the park is a pretty great life.\n",
      "\n",
      "A healthcare project using LangChain is fascinating and very important work. As a large language model myself, I'm very familiar with the principles and applications of frameworks like LangChain.\n",
      "\n",
      "If you or Jack need to brainstorm ideas, work through some logic for your chains, or discuss the capabilities of different models for your project, feel free to ask. I'd be happy to help in any way I can.\n",
      "\n",
      "What is the primary goal of your healthcare project?\n",
      "Human: what all do you know about Max?\n",
      "AI: Based on what you've told me, here is what I know about Max:\n",
      "\n",
      "*   He is your dog.\n",
      "*   He likes to eat chicken.\n",
      "*   He enjoys playing in the park.\n",
      "Last line:\n",
      "Human: Max also has a sister named Bella who is very playful and loves to chase squirrels. Also Jack is a founder of a startup named HealthPlus.\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Got it. I've updated my notes with that new information.\\n\\nIt's lovely to hear that Max has a sister, Bella! A playful squirrel-chaser sounds like a fun addition to the family.\\n\\nI've also noted that Jack is the founder of the startup HealthPlus. That provides great context for the project you're working on together.\\n\\nThanks for keeping me in the loop. How can I help you today?\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_conversation.predict(input=\"Max also has a sister named Bella who is very playful and loves to chase squirrels. Also Jack is a founder of a startup named HealthPlus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ac759a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bella': \"Bella is Max's sister who is very playful and loves to chase \"\n",
      "          'squirrels.',\n",
      " 'HealthPlus': 'HealthPlus is a startup founded by Jack.',\n",
      " 'Jack': \"Jack is John's friend and is working with him on a healthcare \"\n",
      "         'project using langchain. He is the founder of a startup named '\n",
      "         'HealthPlus.',\n",
      " 'John': 'John lives in New York, has a dog named Max, and is working on a new '\n",
      "         'project with his friend Jack.',\n",
      " 'Langchain': 'Langchain is being used by John and Jack for a healthcare '\n",
      "              'project.',\n",
      " 'Max': \"Max is John's dog who likes to eat chicken and play in the park. He \"\n",
      "        'has a sister named Bella.',\n",
      " 'New York': 'John lives in New York.'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(new_conversation.memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3163d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
